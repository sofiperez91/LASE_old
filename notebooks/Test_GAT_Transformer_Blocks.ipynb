{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.GAT_Block import GAT_Block\n",
    "from models.Transformer_Block import Transformer_Block\n",
    "from torch_geometric.utils import to_dense_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "\n",
      "Edge index:\n",
      " tensor([[0, 1, 1, 2, 2],\n",
      "        [1, 0, 2, 0, 1]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[0., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(6, dtype=torch.float32).view(3, 2)+1\n",
    "\n",
    "edge_index = torch.tensor([[ 0, 1, 1, 2, 2],\n",
    "                          [1, 0, 2, 0, 1]])\n",
    "\n",
    "adj_matrix = pyg.utils.to_dense_adj(edge_index).squeeze()\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nEdge index:\\n\", edge_index)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAT Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100., 124.],\n",
      "        [100., 128.],\n",
      "        [ 54.,  72.]], grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0., 10.,  0.],\n",
      "        [10.,  0., 18.],\n",
      "        [14., 18.,  0.]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer=GAT_Block(2,2)\n",
    "\n",
    "layer.lin.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.a.data = torch.ones([1,4])\n",
    "\n",
    "out, att_mtx= layer(node_feats, edge_index, return_attn_matrix=True)\n",
    "\n",
    "\n",
    "print(out)\n",
    "print(att_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17., 39.],\n",
      "        [17., 39.],\n",
      "        [11., 25.]], grad_fn=<ViewBackward0>)\n",
      "tensor([[0.0000e+00, 2.9375e-30, 0.0000e+00],\n",
      "        [1.7139e-15, 0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer=GAT_Block(2,2)\n",
    "\n",
    "layer.lin.weight.data = torch.Tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "layer.a.data = torch.Tensor([[1., 2., 3., 4.]])\n",
    "\n",
    "out, att_mtx= layer(node_feats, edge_index, use_softmax=True, return_attn_matrix=True)\n",
    "\n",
    "\n",
    "print(out)\n",
    "print(att_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[17., 39.],\n",
       "         [17., 39.],\n",
       "         [11., 25.]]),\n",
       " (tensor([[0, 1, 1, 2, 2],\n",
       "          [1, 0, 2, 0, 1]]),\n",
       "  tensor([[2.9375e-30],\n",
       "          [1.7139e-15],\n",
       "          [1.0000e+00],\n",
       "          [1.0000e+00],\n",
       "          [1.0000e+00]])))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "layer = GATConv(2, 2, heads=1, add_self_loops=False)\n",
    "\n",
    "layer.lin_src.weight.data=Tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "layer.att_src.data = Tensor([1, 2])\n",
    "layer.att_dst.data = Tensor([3, 4])\n",
    "\n",
    "with torch.no_grad():\n",
    "   out_feats = layer(node_feats, edge_index, return_attention_weights=True)\n",
    "\n",
    "out_feats\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[118., 146.],\n",
      "        [206., 256.],\n",
      "        [117., 156.]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0., 11.,  0.],\n",
      "        [11.,  0., 39.],\n",
      "        [17., 39.,  0.]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer2=Transformer_Block(2,2)\n",
    "\n",
    "layer2.lin1.weight.data = torch.Tensor([[0.0, 0.0], [0.0, 0.0]])\n",
    "layer2.lin2.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer2.lin3.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer2.lin4.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "\n",
    "out2, att_mtx2= layer2(node_feats, edge_index, return_attn_matrix=True)\n",
    "\n",
    "\n",
    "print(out2)\n",
    "print(att_mtx2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22., 50.],\n",
      "        [28., 64.],\n",
      "        [28., 64.]], grad_fn=<AddBackward0>)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 0.]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer2=Transformer_Block(2,2)\n",
    "\n",
    "layer2.lin1.weight.data = torch.Tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "layer2.lin2.weight.data = torch.Tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "layer2.lin3.weight.data = torch.Tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "layer2.lin4.weight.data = torch.Tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "out2, att_mtx2= layer2(node_feats, edge_index, use_softmax=True, return_attn_matrix=True)\n",
    "\n",
    "print(out2)\n",
    "print(att_mtx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[22., 50.],\n",
       "         [28., 64.],\n",
       "         [28., 64.]]),\n",
       " (tensor([[0, 1, 1, 2, 2],\n",
       "          [1, 0, 2, 0, 1]]),\n",
       "  tensor([[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]])))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import TransformerConv\n",
    "\n",
    "layer2=TransformerConv(2, 2, heads=1, bias = False)\n",
    "\n",
    "layer2.lin_key.weight.data = Tensor([[1.0, 2.0], [3.0, 4.0]]) ## x3 weight\n",
    "layer2.lin_query.weight.data = Tensor([[1.0, 2.0], [3.0, 4.0]]) ## x4 weight\n",
    "layer2.lin_value.weight.data = Tensor([[1.0, 2.0], [3.0, 4.0]]) ## x2 weight\n",
    "layer2.lin_skip.weight.data = Tensor([[1.0, 2.0], [3.0, 4.0]]) ## x1 weight\n",
    "\n",
    "layer2.lin_key.bias.data = torch.Tensor([ 0.0, 0.0])\n",
    "layer2.lin_query.bias.data = torch.Tensor([ 0.0, 0.0])\n",
    "layer2.lin_value.bias.data = torch.Tensor([ 0.0, 0.0])\n",
    "\n",
    "with torch.no_grad():\n",
    "   out_feats = layer2(node_feats, edge_index, return_attention_weights=True)\n",
    "\n",
    "out_feats\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $(XX^TX)$ term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5., 11., 17.],\n",
      "        [11., 25., 39.],\n",
      "        [17., 39., 61.]])\n"
     ]
    }
   ],
   "source": [
    "X_Xt=node_feats@node_feats.T\n",
    "print(X_Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[123., 156.],\n",
      "        [281., 356.],\n",
      "        [439., 556.]])\n"
     ]
    }
   ],
   "source": [
    "X_Xt_X=X_Xt@node_feats\n",
    "print(X_Xt_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "\n",
      "Edge index:\n",
      " tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      "        [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "## Change to a fully connected graph\n",
    "\n",
    "edge_index_2 = torch.tensor([[ 0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
    "                          [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
    "\n",
    "adj_matrix_2 = to_dense_adj(edge_index_2).squeeze()\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nEdge index:\\n\", edge_index_2)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[123., 156.],\n",
      "        [281., 356.],\n",
      "        [439., 556.]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 5., 11., 17.],\n",
      "        [11., 25., 39.],\n",
      "        [17., 39., 61.]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer2=Transformer_Block(2,2)\n",
    "\n",
    "layer2.lin1.weight.data = torch.Tensor([[0.0, 0.0], [0.0, 0.0]])\n",
    "layer2.lin2.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer2.lin3.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer2.lin4.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "\n",
    "out2, att_mtx2= layer2(node_feats, edge_index_2, return_attn_matrix=True)\n",
    "\n",
    "print(out2)\n",
    "print(att_mtx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X^{k+1}\\rightarrow W_0X^k + W_3XX^T W_2X^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa_grafos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
